{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b046ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from captum.attr import IntegratedGradients\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定义 ResNet 模型类\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=None)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# 加载模型和预训练权重\n",
    "model = ResNetClassifier(num_classes=2)\n",
    "model.load_state_dict(torch.load(\"./resnet18_cla.pth\", map_location=\n",
    "                                 device, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# 处理音频文件 和训练时一样\n",
    "def process_audio(audio_path):\n",
    "    audio, sr = librosa.load(audio_path, sr=None) \n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max) \n",
    "    mel_spec_db_resized = cv2.resize(mel_spec_db, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    spectrogram_tensor = torch.tensor(mel_spec_db_resized[np.newaxis, np.newaxis, :, :], dtype=torch.float32) \n",
    "    return spectrogram_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85516d2",
   "metadata": {},
   "source": [
    "#  Visulaisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c037c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from captum.attr import IntegratedGradients, LayerGradCam, Saliency, Occlusion,Lime\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# 自定义颜色映射\n",
    "def create_red_blue_transparent_cmap():\n",
    "    cdict = {\n",
    "        'red':   [(0.0, 0.0, 0.0), (0.5, 1.0, 1.0), (1.0, 1.0, 1.0)],\n",
    "        'green': [(0.0, 0.0, 0.0), (0.5, 1.0, 1.0), (1.0, 0.0, 0.0)],\n",
    "        'blue':  [(0.0, 1.0, 1.0), (0.5, 1.0, 1.0), (1.0, 0.0, 0.0)],\n",
    "        'alpha': [(0.0, 1.0, 1.0), (0.5, 0.0, 0.0), (1.0, 1.0, 1.0)]\n",
    "    }\n",
    "    return LinearSegmentedColormap('RedBlueTransparent', segmentdata=cdict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# IG\n",
    "def generate_ig_heatmap(model, input_tensor, baseline=None, target_class=None):\n",
    "    if baseline is None:\n",
    "        baseline = torch.zeros_like(input_tensor)\n",
    "    input_tensor.requires_grad_()\n",
    "\n",
    "    ig = IntegratedGradients(model)\n",
    "    attributions, _ = ig.attribute(input_tensor, baseline, target=target_class, return_convergence_delta=True)\n",
    "\n",
    "    return attributions.squeeze().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "# Lime\n",
    "def generate_lime_heatmap(\n",
    "    model, spectrogram, target_class, grid_size=(28, 28), n_samples=500, top_percent=10\n",
    "):\n",
    "\n",
    "    lime = Lime(model)\n",
    "\n",
    "\n",
    "    feature_mask = create_feature_mask(spectrogram, grid_size=grid_size)\n",
    "\n",
    "    attributions = lime.attribute(\n",
    "        inputs=spectrogram,\n",
    "        target=target_class,\n",
    "        n_samples=n_samples,\n",
    "        feature_mask=torch.tensor(feature_mask, dtype=torch.long).unsqueeze(0),\n",
    "    )\n",
    "\n",
    "\n",
    "    attributions_np = attributions.squeeze().detach().numpy()\n",
    "\n",
    "    pos_mask = attributions_np >= np.percentile(attributions_np, 100 - top_percent)\n",
    "    neg_mask = attributions_np <= np.percentile(attributions_np, top_percent)\n",
    "    highlighted = np.zeros_like(attributions_np)\n",
    "    highlighted[pos_mask] = attributions_np[pos_mask]\n",
    "    highlighted[neg_mask] = attributions_np[neg_mask]\n",
    "\n",
    "    # 归一化\n",
    "    highlighted_normalized = (highlighted - highlighted.min()) / (\n",
    "        highlighted.max() - highlighted.min()\n",
    "    )\n",
    "    return highlighted_normalized\n",
    "\n",
    "\n",
    "# Grad-CAM\n",
    "def generate_gradcam_heatmap(model, input_tensor, target_class=None, layer_name=None, percentile=90):\n",
    "    layer_gc = LayerGradCam(model, layer_name)\n",
    "    attributions = layer_gc.attribute(input_tensor, target=target_class)\n",
    "    attributions_np = attributions.squeeze().cpu().detach().numpy()\n",
    "\n",
    "\n",
    "    positive_attributions = np.maximum(attributions_np, 0)  \n",
    "    negative_attributions = np.minimum(attributions_np, 0)\n",
    "\n",
    "\n",
    "    if positive_attributions.max() > 0:\n",
    "        positive_attributions /= positive_attributions.max()\n",
    "\n",
    "\n",
    "    if np.any(negative_attributions < 0): \n",
    "        threshold_neg = np.percentile(np.abs(negative_attributions[negative_attributions < 0]), percentile)\n",
    "        negative_attributions[negative_attributions > -threshold_neg] = 0\n",
    "        negative_attributions /= np.abs(negative_attributions).max()\n",
    "    else:\n",
    "        negative_attributions[:] = 0  \n",
    "\n",
    "\n",
    "    attributions_filtered = positive_attributions + negative_attributions\n",
    "\n",
    "    return cv2.resize(attributions_filtered, (input_tensor.shape[-1], input_tensor.shape[-2]))\n",
    "\n",
    "# CAM\n",
    "def generate_cam_heatmap(model, input_tensor, target_class=None, percentile=90):\n",
    "    features = []\n",
    "\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        features.append(output)\n",
    "\n",
    "  \n",
    "    hook = model.resnet.layer4.register_forward_hook(forward_hook)\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "    hook.remove()\n",
    "\n",
    "    feature_map = features[0].squeeze().cpu().numpy()\n",
    "    weights = model.resnet.fc.weight[target_class].detach().cpu().numpy()\n",
    "    cam = np.zeros(feature_map.shape[1:], dtype=np.float32)\n",
    "\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * feature_map[i]\n",
    "\n",
    "\n",
    "    positive_cam = np.maximum(cam, 0)  \n",
    "    negative_cam = np.minimum(cam, 0) \n",
    "\n",
    "\n",
    "    if positive_cam.max() > 0:\n",
    "        threshold_pos = np.percentile(positive_cam[positive_cam > 0], percentile)\n",
    "        positive_cam[positive_cam < threshold_pos] = 0\n",
    "\n",
    "    if np.any(negative_cam < 0): \n",
    "        threshold_neg = np.percentile(np.abs(negative_cam[negative_cam < 0]), percentile)\n",
    "        negative_cam[negative_cam > -threshold_neg] = 0\n",
    "        negative_cam /= np.abs(negative_cam).max()\n",
    "    else:\n",
    "        negative_cam[:] = 0 \n",
    "\n",
    "\n",
    "    cam_filtered = positive_cam + negative_cam\n",
    "\n",
    "    return cv2.resize(cam_filtered, (input_tensor.shape[-1], input_tensor.shape[-2]))\n",
    "\n",
    "\n",
    "\n",
    "# Occlusion\n",
    "\n",
    "def generate_occlusion_heatmap(model, input_tensor, target_class=None, strides=(1, 8, 8), window_shapes=(1, 8, 8), top_percent=10):\n",
    "\n",
    "on = Occlusion(model)\n",
    "    attributions = occlusion.attribute(\n",
    "        input_tensor,\n",
    "        strides=strides,\n",
    "        sliding_window_shapes=window_shapes,\n",
    "        target=target_class\n",
    "    )\n",
    "\n",
    "    attributions_np = attributions.squeeze().detach().numpy()\n",
    "\n",
    "\n",
    "    pos_mask = attributions_np >= np.percentile(attributions_np, 100 - top_percent)\n",
    "    neg_mask = attributions_np <= np.percentile(attributions_np, top_percent)\n",
    "    highlighted = np.zeros_like(attributions_np)\n",
    "    highlighted[pos_mask] = attributions_np[pos_mask]\n",
    "    highlighted[neg_mask] = attributions_np[neg_mask]\n",
    "\n",
    "\n",
    "    highlighted_normalized = (highlighted - highlighted.min()) / (highlighted.max() - highlighted.min())\n",
    "    return highlighted_normalized\n",
    "\n",
    "\n",
    "# for occulsion\n",
    "def create_feature_mask(spectrogram, grid_size=(28, 28)):\n",
    "\n",
    "    \n",
    "    spectrogram_np = spectrogram.detach().cpu().squeeze().numpy()\n",
    "    mask = np.zeros_like(spectrogram_np, dtype=int)\n",
    "\n",
    "\n",
    "    grid_x = np.linspace(0, spectrogram_np.shape[0], grid_size[0] + 1, dtype=int)\n",
    "    grid_y = np.linspace(0, spectrogram_np.shape[1], grid_size[1] + 1, dtype=int)\n",
    "\n",
    "    group_idx = 0\n",
    "    for i in range(grid_size[0]):\n",
    "        for j in range(grid_size[1]):\n",
    "            mask[grid_x[i]:grid_x[i + 1], grid_y[j]:grid_y[j + 1]] = group_idx\n",
    "            group_idx += 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "def visualize_all_with_lime(original_spec, ig_attributions, gc_attributions, cam_attributions, occlusion_map, lime_map, sr, hop_length):\n",
    "    cmap = create_red_blue_transparent_cmap()\n",
    "\n",
    "    zoom_factor = (original_spec.shape[0] / ig_attributions.shape[0],\n",
    "                   original_spec.shape[1] / ig_attributions.shape[1])\n",
    "    ig_attributions_resized = zoom(ig_attributions, zoom_factor, order=1)\n",
    "    gc_attributions_resized = zoom(gc_attributions, zoom_factor, order=1)\n",
    "    cam_attributions_resized = zoom(cam_attributions, zoom_factor, order=1)\n",
    "    occlusion_resized = zoom(occlusion_map, zoom_factor, order=1)\n",
    "    lime_resized = zoom(lime_map, zoom_factor, order=1)\n",
    "\n",
    "    time_axis = np.linspace(0, original_spec.shape[1] * hop_length / sr, original_spec.shape[1])\n",
    "    freq_axis = np.linspace(0, sr / 2, original_spec.shape[0])\n",
    "\n",
    "    fig, axes = plt.subplots(1, 6, figsize=(30, 6))\n",
    "\n",
    "    # 原始 Mel-spectrogram\n",
    "    axes[0].imshow(original_spec, cmap='gray', aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()])\n",
    "    axes[0].set_title(\"Original Mel-Spectrogram\")\n",
    "    axes[0].set_xlabel(\"Time (s)\")\n",
    "    axes[0].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "    # IG\n",
    "    axes[1].imshow(original_spec, cmap='gray', aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()])\n",
    "    axes[1].imshow(ig_attributions_resized, cmap=cmap, aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()], alpha=0.6)\n",
    "    axes[1].set_title(\"Integrated Gradients\")\n",
    "\n",
    "    # Grad-CAM\n",
    "    axes[2].imshow(original_spec, cmap='gray', aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()])\n",
    "    axes[2].imshow(gc_attributions_resized, cmap=cmap, aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()], alpha=0.6)\n",
    "    axes[2].set_title(\"Grad-CAM\")\n",
    "\n",
    "    # CAM\n",
    "    axes[3].imshow(original_spec, cmap='gray', aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()])\n",
    "    axes[3].imshow(cam_attributions_resized, cmap=cmap, aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()], alpha=0.6)\n",
    "    axes[3].set_title(\"Class Activation Map (CAM)\")\n",
    "\n",
    "    # Occlusion\n",
    "    axes[4].imshow(original_spec, cmap='gray', aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()])\n",
    "    axes[4].imshow(occlusion_resized, cmap=cmap, aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()], alpha=0.6)\n",
    "    axes[4].set_title(\"Occlusion\")\n",
    "\n",
    "    # LIME\n",
    "    axes[5].imshow(original_spec, cmap='gray', aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()])\n",
    "    axes[5].imshow(lime_resized, cmap=cmap, aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()], alpha=0.6)\n",
    "    axes[5].set_title(\"LIME\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "audio_path = \"./FakeMusicCaps/MusicCaps/-0Gj8-vB1q4.wav\" \n",
    "input_tensor, original_spec, sr, mel_resized = process_audio(audio_path)\n",
    "\n",
    "\n",
    "output = model(input_tensor)\n",
    "predicted_class = torch.argmax(output).item()\n",
    "\n",
    "\n",
    "ig_attributions = generate_ig_heatmap(model, input_tensor, target_class=predicted_class)\n",
    "gc_attributions = generate_gradcam_heatmap(model, input_tensor, target_class=predicted_class, layer_name=model.resnet.layer4)\n",
    "cam_attributions = generate_cam_heatmap(model, input_tensor, target_class=predicted_class)\n",
    "occlusion_map = generate_occlusion_heatmap(\n",
    "    model, input_tensor, target_class=predicted_class,\n",
    "    strides=(1, 8, 8), window_shapes=(1, 8, 8), top_percent=10\n",
    ")\n",
    " \n",
    "lime_map = generate_lime_heatmap(\n",
    "    model, input_tensor, target_class=predicted_class, grid_size=(32, 32), n_samples=500, top_percent=10\n",
    ")\n",
    "\n",
    "\n",
    "visualize_all_with_lime(original_spec, ig_attributions, gc_attributions, cam_attributions, occlusion_map, lime_map, sr=sr, hop_length=512)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c31b8f6",
   "metadata": {},
   "source": [
    "#  ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db4bd18",
   "metadata": {},
   "source": [
    "## single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010873a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  without mask\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_csv = 'val_dataset_paths.csv'  \n",
    "val_df = pd.read_csv(val_csv)\n",
    "val_paths = val_df['File Path'].values\n",
    "val_labels = val_df['Label'].values\n",
    "\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mel_spec_db = np.load(self.file_paths[idx])\n",
    "        mel_spec_db = torch.tensor(mel_spec_db).unsqueeze(0)  # 添加一个维度\n",
    "        label = self.labels[idx]\n",
    "        return mel_spec_db, label\n",
    "\n",
    "# DataLoader\n",
    "val_dataset = AudioDataset(val_paths, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(mel_spec)\n",
    "            \n",
    "    \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    sensitivity = recall_score(all_labels, all_preds)\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "    print(f'Validation F1 Score: {f1:.4f}')\n",
    "    print(f'Validation Sensitivity (Recall): {sensitivity:.4f}')\n",
    "    print(f'Validation Loss: {avg_loss:.4f}')\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, f1, sensitivity, cm\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "accuracy, f1, sensitivity, cm = evaluate(model, val_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b925cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def mask_positive_contributions(input_tensor, ig_attributions, mask_threshold=90):\n",
    "    positive_contributions = np.maximum(ig_attributions, 0)  # 只保留正向贡献\n",
    "    threshold = np.percentile(positive_contributions, mask_threshold)  # 计算正向贡献的阈值\n",
    "    mask = (positive_contributions >= threshold).astype(float)  # 生成遮盖掩码\n",
    "\n",
    "\n",
    "    masked_percentage = mask.sum() / mask.size * 100\n",
    "#     print(f\"Masked percentage: {masked_percentage:.2f}%\")\n",
    "\n",
    "    masked_tensor = input_tensor.cpu().numpy() * (1 - mask)  # 遮盖正向贡献区域\n",
    "    return torch.tensor(masked_tensor, dtype=torch.float32), masked_percentage\n",
    "\n",
    "\n",
    "def compute_and_mask_ig_features(model, val_loader, mask_threshold=90, max_samples=10):\n",
    "    masked_features = []\n",
    "    masked_labels = []\n",
    "    masked_percentages = []\n",
    "\n",
    "\n",
    "    all_indices = list(range(len(val_loader.dataset)))\n",
    "    random_indices = random.sample(all_indices, max_samples)\n",
    "    subset_loader = DataLoader(Subset(val_loader.dataset, random_indices), batch_size=1, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(subset_loader, desc=\"Computing IG and masking features\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            input_tensor = mel_spec[0].unsqueeze(0)  # [1, channels, height, width]\n",
    "            output = model(input_tensor)  \n",
    "            target_class = torch.argmax(output).item()\n",
    "\n",
    "            ig_attributions = generate_ig_heatmap(model, input_tensor, target_class=target_class)\n",
    "\n",
    "\n",
    "            masked_tensor, masked_percentage = mask_positive_contributions(input_tensor, ig_attributions, mask_threshold)\n",
    "            masked_features.append(masked_tensor.squeeze(0))\n",
    "            masked_labels.append(labels[0].item())\n",
    "            masked_percentages.append(masked_percentage)\n",
    "\n",
    "\n",
    "    avg_masked_percentage = np.mean(masked_percentages)\n",
    "#     print(f\"Average masked percentage: {avg_masked_percentage:.2f}%\")\n",
    "\n",
    "    return torch.stack(masked_features), torch.tensor(masked_labels)\n",
    "\n",
    "\n",
    "def evaluate_with_masked_features(model, masked_features, masked_labels, criterion):\n",
    "    model.eval()\n",
    "    masked_dataset = torch.utils.data.TensorDataset(masked_features, masked_labels)\n",
    "    masked_loader = DataLoader(masked_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(masked_loader, desc=\"Evaluating with masked features\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(mel_spec)\n",
    "            loss = criterion(outputs, labels)  # 计算损失\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    sensitivity = recall_score(all_labels, all_preds)\n",
    "    avg_loss = running_loss / len(masked_loader)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)  \n",
    "\n",
    "\n",
    "    print(f'Masked Validation Accuracy: {accuracy:.4f}')\n",
    "    print(f'Masked Validation F1 Score: {f1:.4f}')\n",
    "    print(f'Masked Validation Sensitivity (Recall): {sensitivity:.4f}')\n",
    "    print(f'Masked Validation Loss: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix (Masked Features)')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, f1, sensitivity, cm\n",
    "\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "masked_features, masked_labels = compute_and_mask_ig_features(\n",
    "    model, val_loader, mask_threshold=90, max_samples=len(val_dataset)\n",
    ")\n",
    "\n",
    "\n",
    "masked_accuracy, masked_f1, masked_sensitivity, masked_cm = evaluate_with_masked_features(\n",
    "    model, masked_features, masked_labels, criterion\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec912c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad-cam\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def mask_positive_contributions_gradcam(input_tensor, gradcam_attributions, mask_threshold=90):\n",
    "    positive_contributions = np.maximum(gradcam_attributions, 0) \n",
    "    threshold = np.percentile(positive_contributions, mask_threshold) \n",
    "    mask = (positive_contributions >= threshold).astype(float)\n",
    "\n",
    "    total_area = np.prod(mask.shape)\n",
    "    masked_area = np.sum(mask)\n",
    "    masked_percentage = (masked_area / total_area) * 100\n",
    "#     print(f\"Masked percentage: {masked_percentage:.2f}%\")\n",
    "    \n",
    "    masked_tensor = input_tensor.cpu().numpy() * (1 - mask)  # 遮盖正向贡献区域\n",
    "    return torch.tensor(masked_tensor, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def compute_and_mask_gradcam_features(model, val_loader, layer_name, mask_threshold=90, max_samples=100):\n",
    "\n",
    "    all_indices = list(range(len(val_loader.dataset)))\n",
    "    random_indices = random.sample(all_indices, max_samples)\n",
    "    subset_loader = DataLoader(Subset(val_loader.dataset, random_indices), batch_size=1, shuffle=False)\n",
    "\n",
    "    masked_features = []\n",
    "    masked_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(subset_loader, desc=\"Computing Grad-CAM and masking features\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            input_tensor = mel_spec  # [1, channels, height, width]\n",
    "            output = model(input_tensor)  \n",
    "            target_class = torch.argmax(output).item()\n",
    "\n",
    "\n",
    "            gradcam_attributions = generate_gradcam_heatmap(\n",
    "                model, input_tensor, target_class=target_class, layer_name=layer_name\n",
    "            )\n",
    "\n",
    "            # 检查是否存在正向贡献，避免空数组报错\n",
    "            if np.any(gradcam_attributions > 0):\n",
    "\n",
    "                masked_tensor = mask_positive_contributions_gradcam(input_tensor, gradcam_attributions, mask_threshold)\n",
    "                masked_features.append(masked_tensor.squeeze(0))  \n",
    "                masked_labels.append(labels.item())\n",
    "            else:\n",
    "                print(f\"Sample skipped: No positive contributions for this sample.\")\n",
    "\n",
    "    if len(masked_features) == 0:\n",
    "        raise ValueError(\"No valid samples with positive contributions were found.\")\n",
    "\n",
    "    return torch.stack(masked_features), torch.tensor(masked_labels)\n",
    "\n",
    "\n",
    "def evaluate_with_masked_features(model, masked_features, masked_labels, criterion):\n",
    "\n",
    "    model.eval()\n",
    "    masked_dataset = torch.utils.data.TensorDataset(masked_features, masked_labels)\n",
    "    masked_loader = DataLoader(masked_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(masked_loader, desc=\"Evaluating with masked features\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(mel_spec)\n",
    "            loss = criterion(outputs, labels) \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    sensitivity = recall_score(all_labels, all_preds, average='weighted')\n",
    "    avg_loss = running_loss / len(masked_loader)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f'Masked Validation Accuracy: {accuracy:.4f}')\n",
    "    print(f'Masked Validation F1 Score: {f1:.4f}')\n",
    "    print(f'Masked Validation Sensitivity (Recall): {sensitivity:.4f}')\n",
    "    print(f'Masked Validation Loss: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix (Masked Features)')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, f1, sensitivity, cm\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "#last layer\n",
    "layer_name = model.resnet.layer4  \n",
    "\n",
    "\n",
    "masked_features, masked_labels = compute_and_mask_gradcam_features(model, val_loader, layer_name, mask_threshold=90, max_samples=len(val_dataset))\n",
    "\n",
    "masked_accuracy, masked_f1, masked_sensitivity, masked_cm = evaluate_with_masked_features(\n",
    "    model, masked_features, masked_labels, criterion\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f1a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def mask_positive_contributions_cam(input_tensor, cam_attributions, mask_threshold=90):\n",
    "    positive_contributions = np.maximum(cam_attributions, 0)  \n",
    "    threshold = np.percentile(positive_contributions, mask_threshold)  \n",
    "    mask = (positive_contributions >= threshold).astype(float)  \n",
    "    masked_tensor = input_tensor.cpu().numpy() * (1 - mask)  \n",
    "    return torch.tensor(masked_tensor, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def compute_and_mask_cam_features(model, val_loader, mask_threshold=90, max_samples=1000):\n",
    "\n",
    "    all_indices = list(range(len(val_loader.dataset)))\n",
    "    random_indices = random.sample(all_indices, min(max_samples, len(all_indices))) \n",
    "    subset_loader = DataLoader(Subset(val_loader.dataset, random_indices), batch_size=1, shuffle=False)\n",
    "\n",
    "    masked_features = []\n",
    "    masked_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(subset_loader, desc=\"Computing CAM and masking features\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            input_tensor = mel_spec  \n",
    "            output = model(input_tensor) \n",
    "            target_class = torch.argmax(output).item()\n",
    "\n",
    "            cam_attributions = generate_cam_heatmap(model, input_tensor, target_class=target_class)\n",
    "\n",
    "\n",
    "            if np.any(cam_attributions > 0):\n",
    "\n",
    "                masked_tensor = mask_positive_contributions_cam(input_tensor, cam_attributions, mask_threshold)\n",
    "                masked_features.append(masked_tensor.squeeze(0))\n",
    "                masked_labels.append(labels.item())\n",
    "            else:\n",
    "                print(f\"Skipping sample with no positive contributions in CAM.\")\n",
    "\n",
    "    if len(masked_features) == 0:\n",
    "        raise ValueError(\"No valid samples with positive contributions were found in CAM.\")\n",
    "\n",
    "    return torch.stack(masked_features), torch.tensor(masked_labels)\n",
    "\n",
    "def evaluate_with_masked_features(model, masked_features, masked_labels, criterion):\n",
    "\n",
    "    model.eval()\n",
    "    masked_dataset = torch.utils.data.TensorDataset(masked_features, masked_labels)\n",
    "    masked_loader = DataLoader(masked_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(masked_loader, desc=\"Evaluating with masked features\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(mel_spec)\n",
    "            loss = criterion(outputs, labels)  \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    sensitivity = recall_score(all_labels, all_preds, average='weighted')\n",
    "    avg_loss = running_loss / len(masked_loader)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds) \n",
    "\n",
    "\n",
    "    print(f'Masked Validation Accuracy: {accuracy:.4f}')\n",
    "    print(f'Masked Validation F1 Score: {f1:.4f}')\n",
    "    print(f'Masked Validation Sensitivity (Recall): {sensitivity:.4f}')\n",
    "    print(f'Masked Validation Loss: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix (Masked Features)')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, f1, sensitivity, cm\n",
    "\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "masked_features, masked_labels = compute_and_mask_cam_features(model, val_loader, mask_threshold=90, max_samples=len(val_dataset))\n",
    "\n",
    " \n",
    "masked_accuracy, masked_f1, masked_sensitivity, masked_cm = evaluate_with_masked_features(\n",
    "    model, masked_features, masked_labels, criterion\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# occ\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def mask_positive_contributions_occlusion(input_tensor, occlusion_attributions, mask_threshold=90):\n",
    "\n",
    "    positive_contributions = np.maximum(occlusion_attributions, 0)  \n",
    "    threshold = np.percentile(positive_contributions, mask_threshold)  \n",
    "    mask = (positive_contributions >= threshold).astype(float)\n",
    "    coverage = np.mean(mask) * 100  \n",
    "    masked_tensor = input_tensor.cpu().numpy() * (1 - mask)\n",
    "    return torch.tensor(masked_tensor, dtype=torch.float32), coverage\n",
    "\n",
    "\n",
    "def compute_and_mask_occlusion_features(model, val_loader, mask_threshold=90, max_samples=10):\n",
    "\n",
    "    all_indices = list(range(len(val_loader.dataset)))\n",
    "    random_indices = random.sample(all_indices, max_samples)\n",
    "    subset_loader = DataLoader(Subset(val_loader.dataset, random_indices), batch_size=1, shuffle=False)\n",
    "\n",
    "    masked_features = []\n",
    "    masked_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(subset_loader, desc=\"Computing Occlusion and masking features\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            input_tensor = mel_spec  \n",
    "            output = model(input_tensor)  \n",
    "            target_class = torch.argmax(output).item()\n",
    "\n",
    "\n",
    "            occlusion_attributions = generate_occlusion_heatmap(model, input_tensor, target_class=target_class)\n",
    "\n",
    "\n",
    "            masked_tensor, coverage = mask_positive_contributions_occlusion(input_tensor, occlusion_attributions, mask_threshold)\n",
    "#             print(f\"Sample coverage: {coverage:.2f}%\") \n",
    "            masked_features.append(masked_tensor.squeeze(0))\n",
    "            masked_labels.append(labels.item())\n",
    "\n",
    "    return torch.stack(masked_features), torch.tensor(masked_labels)\n",
    "\n",
    "\n",
    "def evaluate_with_masked_features(model, masked_features, masked_labels, criterion):\n",
    "\n",
    "    model.eval()\n",
    "    masked_dataset = torch.utils.data.TensorDataset(masked_features, masked_labels)\n",
    "    masked_loader = DataLoader(masked_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(masked_loader, desc=\"Evaluating with masked features\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(mel_spec)\n",
    "            loss = criterion(outputs, labels)  # 计算损失\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(all_labels, all_preds )\n",
    "    sensitivity = recall_score(all_labels, all_preds,)\n",
    "    avg_loss = running_loss / len(masked_loader)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)  \n",
    "\n",
    "\n",
    "    print(f'Masked Validation Accuracy: {accuracy:.4f}')\n",
    "    print(f'Masked Validation F1 Score: {f1:.4f}')\n",
    "    print(f'Masked Validation Sensitivity (Recall): {sensitivity:.4f}')\n",
    "    print(f'Masked Validation Loss: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix (Masked Features)')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, f1, sensitivity, cm\n",
    "\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "masked_features, masked_labels = compute_and_mask_occlusion_features(\n",
    "    model, val_loader, mask_threshold=90, max_samples= len(val_dataset)\n",
    ")\n",
    "\n",
    "masked_accuracy, masked_f1, masked_sensitivity, masked_cm = evaluate_with_masked_features(\n",
    "    model, masked_features, masked_labels, criterion\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd531726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lime\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def mask_positive_contributions_lime(input_tensor, lime_attributions, mask_threshold=90):\n",
    "    positive_contributions = np.maximum(lime_attributions, 0) \n",
    "    threshold = np.percentile(positive_contributions, mask_threshold) \n",
    "    mask = (positive_contributions >= threshold).astype(float) \n",
    "    masked_tensor = input_tensor.cpu().numpy() * (1 - mask)  \n",
    "\n",
    "\n",
    "    mask_coverage = 100 * mask.sum() / mask.size\n",
    "    return torch.tensor(masked_tensor, dtype=torch.float32), mask_coverage\n",
    "\n",
    "\n",
    "def compute_and_mask_lime_features(model, val_loader, mask_threshold=90, grid_size=(28, 28), max_samples=10):\n",
    "    masked_features = []\n",
    "    masked_labels = []\n",
    "    mask_percentages = []  \n",
    "\n",
    "\n",
    "    all_indices = list(range(len(val_loader.dataset)))\n",
    "    random_indices = random.sample(all_indices, max_samples)\n",
    "    subset_loader = DataLoader(Subset(val_loader.dataset, random_indices), batch_size=1, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(subset_loader, desc=\"Computing LIME and masking features\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            input_tensor = mel_spec[0].unsqueeze(0)  # [1, channels, height, width]\n",
    "            output = model(input_tensor)\n",
    "            target_class = torch.argmax(output).item()\n",
    "\n",
    "\n",
    "            lime_attributions = generate_lime_heatmap(\n",
    "                model,\n",
    "                spectrogram=input_tensor,\n",
    "                target_class=target_class,\n",
    "                grid_size=grid_size,\n",
    "                n_samples=500  \n",
    "            )\n",
    "\n",
    "            masked_tensor, mask_coverage = mask_positive_contributions_lime(input_tensor, lime_attributions, mask_threshold)\n",
    "            masked_features.append(masked_tensor.squeeze(0)) \n",
    "            masked_labels.append(labels[0].item())\n",
    "            mask_percentages.append(mask_coverage)  \n",
    "\n",
    "\n",
    "#             print(f\"Sample {len(masked_features)}: Masked percentage = {mask_coverage:.2f}%\")\n",
    "\n",
    "    return torch.stack(masked_features), torch.tensor(masked_labels), mask_percentages\n",
    "\n",
    "\n",
    "def evaluate_with_masked_features(model, masked_features, masked_labels, criterion):\n",
    "    model.eval()\n",
    "    masked_dataset = torch.utils.data.TensorDataset(masked_features, masked_labels)\n",
    "    masked_loader = DataLoader(masked_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(masked_loader, desc=\"Evaluating with masked features\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(mel_spec)\n",
    "            loss = criterion(outputs, labels)  \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    sensitivity = recall_score(all_labels, all_preds)\n",
    "    avg_loss = running_loss / len(masked_loader)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)  \n",
    "\n",
    "\n",
    "    print(f'Masked Validation Accuracy: {accuracy:.4f}')\n",
    "    print(f'Masked Validation F1 Score: {f1:.4f}')\n",
    "    print(f'Masked Validation Sensitivity (Recall): {sensitivity:.4f}')\n",
    "    print(f'Masked Validation Loss: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix (Masked Features)')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, f1, sensitivity, cm\n",
    "\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "masked_features, masked_labels, mask_percentages = compute_and_mask_lime_features(\n",
    "    model, val_loader, mask_threshold=90, grid_size=(28, 28), max_samples=100\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Average Masked Percentage: {np.mean(mask_percentages):.2f}%\")\n",
    "print(f\"Min Masked Percentage: {np.min(mask_percentages):.2f}%\")\n",
    "print(f\"Max Masked Percentage: {np.max(mask_percentages):.2f}%\")\n",
    "\n",
    "\n",
    "masked_accuracy, masked_f1, masked_sensitivity, masked_cm = evaluate_with_masked_features(\n",
    "    model, masked_features, masked_labels, criterion\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c4876",
   "metadata": {},
   "source": [
    "## overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4dfdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def binarize_contributions(contributions, threshold=90):\n",
    "\n",
    "    positive_contributions = np.maximum(contributions, 0)\n",
    "    binarized = (positive_contributions >= np.percentile(positive_contributions, threshold)).astype(int)\n",
    "    return binarized\n",
    "\n",
    "\n",
    "def combine_and_mask_contributions(input_tensor, contributions_list, min_overlap=2):\n",
    "\n",
    "    combined_mask = sum(binarize_contributions(contributions) for contributions in contributions_list)\n",
    "    mask = (combined_mask >= min_overlap).astype(float)\n",
    "    masked_tensor = input_tensor.cpu().numpy() * (1 - mask) \n",
    "\n",
    "\n",
    "    total_elements = mask.size\n",
    "    masked_elements = np.sum(mask)\n",
    "    masked_percentage = (masked_elements / total_elements) * 100\n",
    "\n",
    "    return torch.tensor(masked_tensor, dtype=torch.float32), masked_percentage\n",
    "\n",
    "\n",
    "def process_multiple_xai_techniques(model, input_tensor, target_class):\n",
    "\n",
    "    # Grad-CAM\n",
    "    gradcam_attributions = generate_gradcam_heatmap(\n",
    "        model, \n",
    "        input_tensor, \n",
    "        target_class=target_class, \n",
    "        layer_name=model.resnet.layer4\n",
    "    )\n",
    "    \n",
    "    # Ig\n",
    "    ig_attributions = generate_ig_heatmap(\n",
    "        model, \n",
    "        input_tensor, \n",
    "        target_class=target_class\n",
    "    )\n",
    "    \n",
    "    # CAM\n",
    "    cam_attributions = generate_cam_heatmap(\n",
    "        model, \n",
    "        input_tensor, \n",
    "        target_class=target_class\n",
    "    )\n",
    "    \n",
    "    # Occlusion\n",
    "    occlusion_map = generate_occlusion_heatmap(\n",
    "        model, \n",
    "        input_tensor, \n",
    "        target_class=target_class, \n",
    "        strides=(1, 8, 8), \n",
    "        window_shapes=(1, 8, 8), \n",
    "        top_percent=10\n",
    "    )\n",
    "    \n",
    "    # LIME\n",
    "    lime_map = generate_lime_heatmap(\n",
    "        model, \n",
    "        spectrogram=input_tensor, \n",
    "        target_class=target_class, \n",
    "        grid_size=(32, 32), \n",
    "        n_samples=500,  \n",
    "        top_percent=10\n",
    "    )\n",
    "\n",
    "    return [gradcam_attributions, ig_attributions, cam_attributions, occlusion_map, lime_map]\n",
    "\n",
    "\n",
    "def evaluate_with_combined_contributions(model, val_loader, criterion, mask_threshold=90, min_overlap=2, max_samples=10):\n",
    "\n",
    "    masked_features = []\n",
    "    masked_labels = []\n",
    "    masked_percentages = []\n",
    "\n",
    "\n",
    "    all_indices = list(range(len(val_loader.dataset)))\n",
    "    random_indices = random.sample(all_indices, max_samples)\n",
    "    subset_loader = DataLoader(Subset(val_loader.dataset, random_indices), batch_size=1, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels in tqdm(subset_loader, desc=\"Processing multiple XAI techniques\"):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            input_tensor = mel_spec[0].unsqueeze(0) \n",
    "            output = model(input_tensor) \n",
    "            target_class = torch.argmax(output).item()\n",
    "\n",
    "            # 生成多个 XAI 技术的贡献图\n",
    "            contributions_list = process_multiple_xai_techniques(model, input_tensor, target_class)\n",
    "\n",
    "\n",
    "            masked_tensor, masked_percentage = combine_and_mask_contributions(input_tensor, contributions_list, min_overlap=min_overlap)\n",
    "            masked_features.append(masked_tensor.squeeze(0)) \n",
    "            masked_labels.append(labels[0].item())\n",
    "            masked_percentages.append(masked_percentage)\n",
    "\n",
    "    masked_features = torch.stack(masked_features)\n",
    "    masked_labels = torch.tensor(masked_labels)\n",
    "\n",
    "\n",
    "    accuracy, f1, sensitivity, cm = evaluate_with_masked_features(model, masked_features, masked_labels, criterion)\n",
    "\n",
    "\n",
    "    avg_masked_percentage = np.mean(masked_percentages)\n",
    "    print(f\"Average Masked Percentage: {avg_masked_percentage:.2f}%\")\n",
    "\n",
    "    return accuracy, f1, sensitivity, cm, avg_masked_percentage\n",
    "\n",
    "# min_overlap 2-5, the key paramter\n",
    "accuracy, f1, sensitivity, cm, avg_masked_percentage = evaluate_with_combined_contributions(\n",
    "    model, val_loader, criterion, mask_threshold=90, min_overlap=, max_samples=len(val_dataset)\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Masked Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Masked Validation F1 Score: {f1:.4f}\")\n",
    "print(f\"Masked Validation Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Average Masked Percentage: {avg_masked_percentage:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
